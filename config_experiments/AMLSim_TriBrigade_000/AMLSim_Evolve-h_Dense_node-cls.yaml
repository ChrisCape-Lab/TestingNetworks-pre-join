# The name of the experiment, composed with the main element of the network. It is used to distinguish the experiment folder for results
name: AMLSim_Evolve-h_Dense_node-cls


# The name of the dataset, used to build the correct dataset for the experiment
data: AMLSim

# The type of the Model. Available: 'GCNClassifier', 'Autoencoder'
model_type: GCNClassifier

use_cuda: True
use_logfile: True

# The seed of all the random functions, set in order to make the experiments reproducible
seed: 1234


# The argument for the configuration of the GraphDataset object of the dataset
dataset_args:
    # the folder in which are saved the datasets_output of the dataset to be loaded
    folder: ../datasets_output/processed/AMLSim

    # The name of the file which contains the nodes and their features
    nodes_file: AMLSim_accounts.csv

    # The name of the file in which are stored the edges and their features
    edges_file: AMLSim_transactions.csv

    # Specify if the adjacency matrix must use edge weight or a simple 1 or 0 to define whether edges are present
    weighted: False

    # Specify if the adjacency matrix must be directed or undirected (symmetric)
    directed: False

    # specify if the nodes features need to be normalized
    normalize: True

    # specify if ML transactions are excluded
    lawful: False


# The arguments for the configuration of all the elements of the 'dataloader' folder
dataloder_args:
    # The type of task that the network should perform. Available: 'node_cls', 'edge_cls', 'link_pred'
    task: node_cls

    # Specify if the adjacency matrix needs to be normalized for spectral convolution
    normalize_adj: True

    # Specify the dimension of the sample, which is the amount of time instant datasets_output that are passed each time to the network
    time_window: 6

    # Specify if there is a temporal dependency among the datasets_output (basically, if shuffle or not the datasets_output)
    is_static: False

    # Specify the division among the train set, validation set and test set
    split_proportions: [0.4, 0.3, 0.3]

    # Some additive dataloader parameters used for cuda load
    data_loading_params:
        batch_size: 1
        num_workers: 0


# The arguments for the configuration of the 'Model'. specify both the Network and Classifier arguments together with the Model type
model_args:
    # The type of the Model. Available: 'GCNClassifier', 'Autoencoder'
    type: GCNClassifier

    # [GCNClassifier] The type of the connector. Available: 'Normal', 'Flatten' and 'Iterative'
    connector: Normal

    # The arguments for the configuration of the 'Network'
    network_args:
        # the type of the network that extract the features. Available: 'Evolve-h', 'Evolve-o', 'addGraph', 'GAT', ...
        network: Evolve-h

        # The number of features that the network takes as input. If set to 'auto' is automatically calculated according to the network
        feats_per_node: auto

        # The output dimensions of all hidden layers of the network, if it's a layered network
        layers_dim: [10]

        # The output dimension of the network
        output_dim: 8

        # The activation function that the network must use
        activations: ReLU

        # Specify the probability for the dropout layer
        dropout: 0.1

        # Specify if introduce a skip connection that concatenate the input to the output of the layer
        skipfeats: False

    # The arguments for the configuration of the 'Classifier'
    classifier_args:
        # The type of the classifier. Available: 'Linear', 'Dense', 'EdgeClassifier', 'GAT', ...
        classifier: Dense

        # The type of output of the classifier, can be logits (NxC) or probabilities (Nx1). Available: 'Logits' or 'Probabilities'
        output_type: Logits

        # The input features of the classifier.
        input_feats: 8

        # The output dimensions of all hidden layers of the classifier, if it's a layered classifier
        layers_dim: [6]

        # The output dimension of the classifier. If is set to 'auto' it is automatically computed by the program
        output_dim: auto

        # [DENSE] Specify the usage of the bias or not in the Dense Classifier
        bias: False


# the arguments for the training phase
trainer_args:
    # The different learning rates of the network and classifier
    optimizer_args:
        # The learning rate of the network's optimizer
        network_lr: 0.01

        # The weight decay of the network's optimizer
        network_wd: 0.01

        # The learning rate of the classifier's optimizer
        classifier_lr: 0.01

        # The weight decay of the network's optimizer
        classifier_wd: 0

    # The epoch arguments
    epochs_args:
         # The number of epoch for training (maximum value for real, there' early stopping)
        num_epochs: 1000

        # The number of steps AFTER WHICH the gradient is updated. Default: 1
        steps_accum_gradients: 1

        # The number of epoch BEFORE starting the validation procedure. Default: 0
        eval_after_epochs: 0

        # The patience for early stopping (number of epoch with bad val loss after which stop)
        early_stop_patience: 15

    # The loss function's arguments
    loss_args:
        # The loss type to be used. Can be "Binary_cross_entropy", ...
        loss: cross_entropy

        # The list of weights for each class to "balance" the class imbalance. If set to 'auto' is automatically calculated by the program
        class_weights: auto

        # The evaluation metric used to define the best epoch. Available: Loss, Accuracy, Error, MAP, MRR, bACC, Precision, Recall, F1.
        eval_measure: bACC

comments:
    - Test with skipfeats, a window of 7, network size a little bigger and Probs
